---
title: "Tarea Parte 1 Estefania Garcia"
author: "Estefania Garcia"
date: "17/2/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Ejercicio de Evaluación 1
## Análisis de componentes principales y Cluster
El fichero provincias contiene información socio-economica de las provincias españolas. Para reducir el número de variables e intentar encontrar relaciones, tanto entre variables como entre provincias, realizar los siguientes apartados.

```{r librerías necesarias, echo=FALSE, warning=FALSE, message= FALSE}

#install.packages("factoextra")
#install.packages("pastecs")
#install.packages("FactoMineR")
#install.packages("Cluster")
#install.packages("NbClust")
#install.packages("heatmaply")
library(readxl)
library(ggplot2)
library(factoextra)
library(pastecs)
library(knitr)
library(FactoMineR)
library(corrplot)
library(cluster)
library(NbClust)
library(heatmaply)
```


```{r estadisticos basicos, echo=FALSE}
#Importamos los datos:
Provincias<- read_excel("C:/Users/User/Documents/Estefania/Master/06. Minería de datos y Modelización Predictiva/Juana Maria Alonso/Tarea/Provincias.xlsx")
datos<- as.data.frame(Provincias)
rownames(datos)<- datos[,1]
provincias_esp<- datos[, -1]
#Descriptivos
tabla1<-stat.desc(provincias_esp, basic=FALSE)
knitr:: kable(tabla1, digits=2, caption= 'Estadísticos Descriptivos')
```

**1. Calcular la matriz de correlaciones y su representación gráfica ¿Cuáles son las variables más correlacionadas de forma inversa?**

```{r correlación}
#Calcular la matriz de correlación 
R<- cor(provincias_esp, method="pearson")
knitr::kable(R, digits=2, caption= "Correlaciones")
corrplot(R, type="upper", order="hclust", tl.col="black", tl.srt= 90)
```
Las variables más correlacionadas de forma inversa son: Mortalidad con Natalidad (-0,74) y Mortalidad con Tasa de Actividad (-0,73). Esto quiere decir que cuando una de ellas incrementa la otra disminuye. Luego, como podemos observar en el gráfico, tenemos muchas variables correlacionadas fuertemente de manera positiva, es decir, que cuando una incrementa la otra también. 


**2. Realizar un análisis de componentes principales sobre la matriz de correlaciones, calculando 7 componentes. Estudiar los valores de los autovalores obtenidos y las gráficas que los resumen. ¿Cuál es el número adecuado de componentes?**

```{r PCA, warning=FALSE}
fit<- PCA(provincias_esp, scale.unit = TRUE,ncp= 7, graph=TRUE)
eig<- get_eigenvalue(fit)

knitr::kable(eig, digits=2, caption= "Autovalores")
fviz_eig(fit, addlabels=TRUE)
```
El primer autovalor, explica el 63,70% de las variables.El segundo explica el 14,23% y el tercero explica el 9,08% de la varianza de las variables originales. Si acumulamos los porcentajes estas tres dimensiones explican el 87,01% de las 18 variables originales. Decidimos hacer un análisis con 3 componentes. 



**3. Hacer de nuevo el análisis sobre la matriz de correlaciones pero ahora indicando el número de componentes principales que hemos decidido retener (que expliquen aprox. el 90%) Sobre este nuevo análisis contestar los siguientes apartados: **


```{r PCA definitivo, warning=FALSE}
fit<- PCA(provincias_esp, scale.unit = TRUE,ncp=3 , graph=TRUE)
```
**3.a. Mostrar los coeficientes para obtener las componentes principales ¿Cuál es la expresión para calcular la primera componente en función de las variables originales?**

```{r coeficientes, warning=FALSE}
knitr::kable(fit$svd$V, digits=2, caption= "Autovectores")
fit$svd$V
```
La expresión para calcular la primera componente en función de las variables originales es la siguiente: 




**3.b. Mostrar una tabla con las correlaciones de las Variables con las Componentes Principales. Para cada componente indicar las variables con las que está más correlacionada.**

```{r tabla corr}
var<- get_pca_var(fit)
knitr::kable(var$cor, digits= 2, caption= "Correlaciones de la CP con las variables")
```
La componente 1 está más correlacionada con las variables: Población, NumEmpresas, Industria, Construcción, CTH, Infor, AFS, APT, Ocupados,PIB,VS y TVF. La componente 2 está más correlacionada con Natalidad, Mortalidad, IPC, TasaActividad y TasaParo.Por su parte la componente 3 está más correlacionada únicamente con la variable CANE.  

**3.c.Comentar los gráficos que representan las variables en los planos formados por las componentes, intentando explicar lo que representa cada componente. **

```{r graficos de componentes, warning=FALSE}
fviz_pca_var(fit, axes= c(1,2), col.var="cos2", gradient.cols=c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)
```
Las coordenadas de cada variable son el coeficiente de correlación entre la variable y las nuevas componentes. Así la variable Mortalidad está negativamente correlacionada con la componente 1 y la componente 2. CANE es la variable peor representada por estas dos componentes. Mientras que la segunda componente recoge sobretodo la información de las variables Natalidad, Mortalidad y TasaParo.   

```{r grafico 1,3, warning=FALSE}
fviz_pca_var(fit, axes= c(1,3), col.var="cos2", gradient.cols=c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)
```
Las variables peor representadas por las componentes 1 y 3 son Natalidad, Mortalidad y TasaParo. La variable CANE recoge gran parte de la información de la tercera componente, mientras que las variables relacionadas al número de empresas, población, ocupados y PIB se encuentran recogidas por la primera componente con una correlación muy grande y positiva entre ellas ya que se encuentran casi solapadas las flechas en un angulo muy agudo.  

```{r grafico 2, 3, warning=FALSE}
fviz_pca_var(fit, axes= c(2,3), col.var="cos2", gradient.cols=c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)
```
Las variables CANE y TasaParo están positivamente correlacionadas con las componentes 3 y 2. Por otro lado IPC se correlaciona negativamente con ambas componentes. Las variables relativas al número de empresas, Población, ocupados y PIB no se encuentran representadas por estas componentes ya que son las felchas minimas próximas al valor de cero y pintadas en azul. 


**3.d. Mostrar la tabla y los gráficos que nos muestran la proporción de varianza de cada variable que es explicada por cada componente. ¿Cuál de las variables es la que está peor explicada?**

```{r cosenos al cuadrado}
knitr:: kable (var$cos2, digits=2, caption= "Cosenos al cuadro")
```


```{r grafico cosenos cuadrado}
corrplot(var$cos2, is.corr=FALSE)

```
```{r grafico variabilidad}
fviz_cos2(fit, choice= "var", axes=1:3)

```
Gráficamente se muestra que la varianza de las Variables Mortalidad, Natalidad, IPC, TasaParo, y Tasa Actividad es explicada por la componente dos, mientras que la componente 3 explica sólo a la variable CANE y el resto de variables son explicadas por la primera componente. 

Luego, en el gráfico de barras mostramos el porcentaje de la varianza de las variables que es explicada por los tres componentes en total. Observamos que la variable VS es la que está menos explicada (49% en total si sumamos las 3 componentes.)

**3.e. Mostrar la tabla y los gráficos que nos muestran el porcentaje de la varianza de cada componente que es debido a cada variable. ¿Qué variables contribuyen más a cada Componente?**


```{r contribución}
knitr:: kable(var$contrib, digits=2, caption= "Contribuciones")
corrplot(var$contrib, is.corr=FALSE)
fviz_contrib(fit, choice="var", axes=2, top=10)
fviz_contrib(fit, choice="var", axes=1, top=10)
fviz_contrib(fit, choice="var", axes=3, top=10)
```
La contribución de una variable a una componente es el porcentaje de varianza de la componente que proviene de cada variable. 

El 27,79% de la varianza de la componente 2 viene de Mortalidad, el 24,54% de Natalidad y un 21,30% de TasaParo. Es un punto a destacar que el 43,13%, es decir casi la mitad, de la varianza de la componente 3 viene sólo de la variable CANE. Mientras que las varianzas de la componente 1 se distribuyen de manera más uniforme entre las variables que en su mayoría contribuyen en torno a un 8% (la mayor contribución es Ocupados con un 8,67%).


**3.f.Sobre los gráficos que representan las observaciones en los nuevos ejes y el gráfico BIplot, teniendo en cuenta la posición de las provincias en el gráfico. Comentar las provincias que tienen una posición más destacada en cada componente, en positivo o negativo. ¿Qué significa esto en términos socioeconómicos para estas provincias?**


```{r individualsPCA, warning=FALSE}
fviz_pca_ind(fit, axes= c(1,2), gradient.cols= c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)

 #Representación conjunta de los individuos y las variables en los planos de las CP.

fviz_pca_biplot(fit, repel=TRUE,axes= c(1,2), col.var= "#2E9FDF", col.ind= "#696969")
```

De acuerdo al gráfico biplot, podemos ver que la provincia Zamora tiene una tasa elevada de Mortalidad, mientras que Melilla y Ceuta tienen una tasa de paro y natalidad elevada en comparación a otras. Madrid y Barcelona destacan por tener el valor màs alto de PIB, número de empresas, población y ocupados. 



```{r individualsPCA2y3, warning=FALSE}
fviz_pca_ind(fit, axes= c(2,3), gradient.cols= c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)

 #Representación conjunta de los individuos y las variables en los planos de las CP.

fviz_pca_biplot(fit, repel=TRUE,axes= c(2,3), col.var= "#2E9FDF", col.ind= "#696969")
```
Este gráfico nos muestra que por ejemplo: mientras Jaén tiene un valor grande de CANE, Madrid tiene un valor de esta variable muy pequeño ya que se en cuentra en sentido opuesto. Por otro lado también podemos ver que Ceuta y Melilla tienen una tasa de natalidad elevada y además un valor muy bajo en la tasa de mortalidad. Lo opuesto ocurre con la provincia de Zamora o Ourense. 



```{r individualsPCA1y3, warning=FALSE}
fviz_pca_ind(fit, axes= c(1,3), gradient.cols= c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)

 #Representación conjunta de los individuos y las variables en los planos de las CP.

fviz_pca_biplot(fit, repel=TRUE,axes= c(1,3), col.var= "#2E9FDF", col.ind= "#696969")
```
Este gráfico nos muestra que la provincia con un valor más alto de CANE es Jaén, como ya habíamos comentado. Destacan también las provincias de Valencia y Alicante con valores elevados de Viviendas Secundarias (VS) mientras que por estar en sentido opuesto Ceuta y Melilla tendrán muy pocas viviendas secundarias. 


**3.g. Si tuvieramos que construir un índice que valore de forma conjunta el desarrollo económico de una provincia, cómo se podría construir utilizando una combinación lineal de todas las variables. ¿Cuál sería el valor de dicho índice en Madrid? ¿Cuál sería su valor en Melilla?**

```{r valores de individuos en las CP, warning=FALSE}
ind<- get_pca_ind(fit)
knitr:: kable(ind$coord, digits=2, caption= "Valores de los individuos en las CP")
fviz_pca_ind(fit, col.ind= "cos2", gradient.cols= c("#00AFBB", "#E7B800", "#fc4e07"), repel=TRUE)
```

Representamos los valores que toman las provincias en las nuevas variables como una combinación lineal. Como se muestra en la tabla, estos valores están en torno al cero, porque están calculados a partir de los datos estandarizados y los vectores son ortogonales. Valores negativos significan que esa provincia para ese indice toma un valor por debajo de la media. Si el valor es positivo, indica que está por encima de la media. 

Como observamos en el plano de las componentes las coordenadas nos muestran el valor que toman en esa componente. Por ejemplo, Madrid y Barcelona, que toman valores positivos en la componente 1 pero un valor negativo en la componente 2 nos indican que se encuentran muy por encima de los valores medios de los indicadores de PIB, número de empresas, población y ocupados pero valores inferiores a la media en las dos componentes restantes que representan la explotación agraria y la tasas de mortalidad, natalidad y paro. 

Un ejemplo opuesto es Ceuta, Melilla y Almería que son provincias en las cuales hay pocos ocupados, contribuyen menos al PIB y por ende tienen un menor número de empresas, es decir, tienen un valor menor a la media de la componente 1. Sin embargo, tienen un valor superior a la media de las componentes dos. Esto significa que en promedio su tasa de natalidad, mortalidad y paro es mayor a la del resto y sólo Almería cuenta con un valor de CANE positivo (componente 3).

Los valores para Madrid son 16.78, -0.37 y -0.85 (para las tres componentes en orden). Mientras que para Melilla los valores son: -2.22, 4.78 y -1.91.

**4. Representar un mapa de calor de la matriz de datos, estandarizado y sin estandarizar para ver si se detectan inicialmente grupos de provincias.** 

```{r mapa de calor inicial}
#Exploración inicial de los datos. 
#ggheatmap(as.matrix(provincias_esp), seriate="OLO")
#heatmaply(provincias_esp, seriate = "mean", row_dend_left = TRUE, plot_method="plotly")
```

```{r distancias sin estandarizar}
#Calculamos las distancias con los valores sin estandarizar
d<- dist(provincias_esp, method="euclidean")
d6<-as.matrix(d)[1:6,1:6]
knitr:: kable(d6,digits=2, caption= "Distancias")
fviz_dist(d, show_labels=TRUE)
ggheatmap(as.matrix(d), seriate="mean")
```


```{r distancias estandarizadas}
datos_ST <- scale(provincias_esp)
d_st<- dist(datos_ST, method= "euclidean")
d_st6<- as.matrix(d_st)[1:6, 1:6]
knitr:: kable(d_st6, digits= 2, caption= "Distancias estandarizadas")
#Visualizamos
fviz_dist(d_st, show_labels = TRUE)
#Mapa de calor estadanrizado
ggheatmap(as.matrix(d_st), seriate= "mean")



```


**5. Realizar un análisis jerárquico de clusters para determinar si existen grupos de provincias con comportamiento similar.** 

**5.a. A la vista del dendograma ¿Cuantos clusters recomendarias?**

```{r dendograma sin estandarizar}
res.hc <- hclust(d, method="ward.D2")
fviz_dend(res.hc, cex=0.5)
```


```{r dendograma estandarizado}
res.hc_st<- hclust(d_st, method= "ward.D2")
fviz_dend(res.hc_st,cex=0.5)
```


**5.b. Representar los individuos agrupados segun el número de clusters elegido.** 

Decidimos agrupar por cinco clusters ya que eso nos indican los dendogramas. Observamos un tamaño de los clusters por número de observaciones razonable. 

```{r agrupando por cluster}
grp <- cutree(res.hc_st, k=5)
head(grp, n=4)
knitr::kable(table(grp), caption= "Número de individuos por clúster")
```

```{r cluster color, message= FALSE, warning= FALSE}
#Representamos el dendograma marcando los cluster con color.
fviz_dend(res.hc_st, k=5, cex= 0.5, k_colors= c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#0F9D58", "#fc0394"), color_labels_by_k = TRUE, rect= TRUE)



fviz_cluster(list(data = datos_ST, cluster = grp),
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07", "#0F9D58", "#fc0394"), 
             ellipse.type = "convex", # Concentration ellipse
             repel = TRUE, # Avoid label overplotting (slow)
             show.clust.cent = FALSE, ggtheme = theme_minimal())

```



**5.c.¿Qué número óptimo de clusters nos indican los criterios Silhoutte y de Elbow?**

El criterio de Elbow elige como número óptimo de cluster en el que la variabilidad total intra cluster ya no se reduce de forma significativa al aumentar uno más. 

```{r ELBOW}
fviz_nbclust(datos_ST, kmeans, method= "wss")+
  geom_vline(xintercept=5, linetype= 2)+
  labs(subtitle="Elbow Method")

```
A partir de 5 cluster se observa una menor variabilidad entre cluster. Lo cual confirma lo que observamos en el agrupamiento jerárquico. Cinco clusters pareciera óptimo.

A continuación se utilizará el método de la silueta que es una medida de cuán compactos son los clusters y cuán separados están unos de otros. Si la silueta media es superior a 0.5 se produce una partición de los datos razonable, mientras que un valor por debajo de 0.2 indica que los datos no exhiben ninguna estructura de clúster. 
  
```{r silhouette}
fviz_nbclust(datos_ST, kmeans, method= "silhouette")+
  labs(subtitle= "Silhouette Method")
```

El método silueta, nos indica que después de tres los grupos no parecieran exhibir caracteristicas de cluster.  Aunque dos es un número muy pequeño de clúster (vemos otro repunte en 5), dado que queremos cluster compactos con distancias grandes entre ellos podríamos considerar dos como un óptimo por su valor elevado.  


**5.d. Con el número de clusters decidido en el apartado anterior realizar un agrupamiento no jerárquico.**

Inicialmente optaremos por hacer un agrupamiento de cinco clusters ya que tanto los dendogramas como el criterio de Elbow parecían indicar que esto era adecuado. Luego evaluaremos su calidad, y despues ajustaremos si es necesario de acuerdo al criterio de la silueta. 

```{r semilla}
RNGkind(sample.kind = "Rejection")
set.seed(1234)
```
```{r compute k means}
km.res<- kmeans(datos_ST, 5)
#head(km.res$cluster, 20)

```
```{r cluster no jerarquico}
#print(km.res)
```
Ahora, haremos un agrupamiento no jerárquico de acuerdo al criterio de la silueta, es decir, 2 clúster. 

```{r compute k means 2 cluster}
km.res2<- kmeans(datos_ST, 2)
#head(km.res$cluster, 20)
#print(km.res2)
```

**5.d.i Representar los clusters formados en los planos de las componentes principales. Relacionar la posición de cada cluster en el plano con lo que representa cada componente principal.**

Evaluaremos primero el gráfico del agrupamiento por cinco clúster. 

```{r CLUSTER Y COMPONENTES}
fviz_cluster(km.res, datos_ST)
```
El gráfico anterior ya nos alerta de un problema grave en la calidad de nuestros clúster ya que hay solapamientos entre grupos de observaciones. Recordemos que queremos que los cluster sean los más homogeneos posible a lo interno pero lo más diferentes entre ellos. Los solapamientos podrían indicar que las observaciones están mal clasificadas ya que se aproximan más a valores de otros clusters que al propio. 

Evaluaremos el gráfico con dos clústers: 

```{r CLUSTER Y COMPONENTES 2}
fviz_cluster(km.res2, datos_ST)
```
Este segundo gráfico, a pesar de que incluye un clúster con multitud de observaciones y otro sólo con dos (Madrid y Barcelona) parece cumplir con los principios que definen correctamente a un cluster, es decir ser compacto y distante de los otros grupos. A nivel de análisis también tiene mucho más sentido tener sólo dos clúster. Esto nos indica que en términos ecónomicos sólo dos provincias aportan más a los indicadores que el resto del país. 

Recordemos que en el plano de las componentes principales la Dimensión1 representa las variables relacionadas al número de empresas en distintos sectores, población y ocupación. Mientras que la Dimensión dos representa la tasa de mortalidad, natalidad y paro. Entonces podemos interpretar que el cluster dos contiene provincias en donde hay elevadas tasas de natalidad y mortalidad, pero también paro, así como provincias donde las tasas anteriores son bajas pero la característica de todo el clúster en conjunto es que está menos densamente poblado y tiene menor actividad economica que las provincias del cluster 1 (Madrid y Barcelona) las cuales concentran la mayor parte del PIB, empleos y están densamente pobladas. Se observa pues, la migración hacia estas ciudades en búsqueda de oportunidades económicas en una España muy desigual en cuanto a los criterios descritos y centralizada su actividad en dos urbes. 

**5.d.ii. Evaluar la calidad de los clusters.**

Debemos recordar que las siluetas se encuentran entre -1 y 1. Si la silueta se encuentra próxima a 1 quiere decir que la observación se encuentra bien agrupada. Si la silueta es negativa indica una mala agrupación para la observación. 

```{r calidad silhouette cluster 5}
sil<- silhouette(km.res$cluster, dist(datos_ST))
rownames(sil)<-rownames(datos)
head(sil[, 1:3])
fviz_silhouette(sil)
```
Como intuimos en el gráfico anterior. La agrupación de cinco clúster no es la adecuada, para observaciones en el cluster 2, 3 y 5 tenemos valores negativos.Esto quiere decir que las observaciones cuyo valor es negativo se encuentran mal agrupadas. 

Si comprobamos la calidad de los clusters recomendados por el criterio silueta vemos que efectivamente la agrupación está correcta porque no presenta valores negativos. Es por esto que decidimos que el mejor modelo de agrupación es el de dos clusters. 


```{r calidad silhouette cluster 2}
sil<- silhouette(km.res2$cluster, dist(datos_ST))
rownames(sil)<-rownames(datos)
head(sil[, 1:3])
fviz_silhouette(sil)
```

**5.e. Explicar las provincias que forman cada uno de los clusters y comentar cuales son las características socioeconómicas que las hacen pertenecer a dicho cluster.** 

Una vez decidido que la mejor agrupación es de dos cluster analizaremos las características de cada uno. 

```{r SORT BY CLUSTER}
ordenado <- sort(km.res2$cluster)
knitr:: kable(ordenado, digits=2, caption= "Provincia y cluster")
```

Calculamos los estadísticos estandarizados pero sabemos que por la dificultad intrepretativa debemos utilizar la función aggregate para obtener los estadísticos sobre las variables originales. 

```{r estadísticos std}
knitr:: kable(km.res2$centers, digits=2, caption= "Estadísticos de los clusters datos STD")
```

```{r estadísticos originales}
est_clus<- aggregate(provincias_esp, by=list(km.res2$cluster), mean)
knitr::kable(est_clus, digits=2, caption="Estadísticos de los clusters")
```
Efectivamente observando los estadísticos reafirmamos lo que mencionábamos anteriormente. El grupo 1 de Madrid y Barcelona, concentra la mayor parte de la población (casi seis millones), y la mayor parte de las industrias y empresas, con la consecuente mayor aportación al PIB. Por su parte el grupo dos concentra la mayor parte de las explotaciones agrarias (CANE) y tiene una tasa de paro ligeramente mayor. 



